
这篇论文提出一个新的架构，ArchTM架构

故障原子事务是在具有崩溃一致性的持久内存(PM)上访问和操作数据的关键机制。作者发现，在传统的PM事务系统中，元数据修改中的小的随机写入和位置无关的内存分配与PM体系结构不匹配。

PM体系结构的性能表征引导作者重新思考PM事务的设计。基于日志的事务有双重写问题，因为创建日志和就地更新数据。对PM过多的写操作与PM上较差的写性能不匹配。虽然基于cow的事务避免了这个问题，但是由于元数据更新，会造成性能开销，这会导致许多小的写操作与PM内部块大小不一致

因此作者也遵循了PM事物系统的两大设计原则，这边也讲一下事务的系统的哪量大原则：避免小写和鼓励顺序写

什么是小写呢？一般情况下在向内存写数据时，数据也是有大有小的，但是小于256字节的数据一般都是小写，PM中的小写会导致写放大，因为小写中的数据必须与PM中的内部写块大小(256字节)对齐，这会浪费内存带宽并延迟事务，但是研究表明，当事务系统执行写操作时，超过78%的数据对象小于64字节。

故障原子事务是在具有崩溃一致性的持久内存(PM)上访问和操作数据的关键机制。我们发现，在传统的PM事务系统中，元数据修改中的小的随机写入和位置无关的内存分配与PM体系结构不匹配。我们提出了ArchTM，一个基于两个设计原则的PM事务系统:避免小写和鼓励顺序写。ArchTM是copy-on-write (CoW)系统的变体，用于减少对PM的写流量。与传统的CoW方案不同，ArchTM通过DRAM上的可扩展查询表减少了元数据修改。ArchTM引入了一个注释机制来确保崩溃的一致性，并在内存分配中引入了一个位置感知的数据路径来增加PM设备内的可合并写。


> 顺序写

顺序写(ordered write)模型： 规定一组原子的数据存储单元间有一定的因果顺序(或依赖关系)，先存的数据不依赖于后存的数据，因此，当数据按这个顺序存储到存储设备的过程中，无论何时发生断电或崩溃，系统仍是一致的。



> 主要贡献

- 作者揭示了实际PM硬件的性能特征，并指出了代表性PM事务中的性能问题。这是由于传统的PM事务设计忽视了PM体系结构的特点造成的。

- 作者确定了实现高性能PM事务的两个基本权衡。我们引入了一个新的PM事务设计ArchTM，它根据PM体系结构定制，打破了折衷。
  
- 在PM硬件上使用微基准测试和实际工作负载，ArchTM平均比最先进的PM事务系统PMDK、Romulus、DUDETM和Oracle系统高出58倍、5倍、3倍和7倍。



ArchTM引入了一个注释机制来确保崩溃的一致性，并在内存分配中引入了一个位置感知的数据路径来增加PM设备内的可合并写。

> 什么是双重写？

双重写入描述了您在两个个系统（例如数据库和Apache Kafka）中更改数据时的情况，而没有额外的层来确保两个服务上的数据一致性。
只要两个操作都成功，一切就OK了。即使第一笔交易失败，也还是可以的。但是，如果您成功提交了第一笔交易而第二笔交易失败，则说明您遇到了问题。您的系统现在处于不一致状态，没有容易修复的方法。

> 什么是DRAM？

``RAM，Random-Access Memory``，即随机存取存储器，其实就是内存，断电会丢失数据。主要分为``SRAM``（static）和``DRAM``（dynamic)。主要的区别在于存储单元，``DRAM``使用电容电荷进行存储。需要一直刷新充电。SRAM是用锁存器锁住信息，不需要刷新。但也需要充电保持。关于DRAM，其基本的存储单元如下，利用一个晶体管进行控制电容的充放电。



> 什么是PM

它具有类似于内存的方面也有类似于存储的方面，但是通常不会替换内存或存储。相反，持久性内存是第三层，与内存和存储结合使用。

持久性内存性能（吞吐量、延迟、带宽）比NAND闪存好，但比DRAM低
相比DRAM，顾名思义，持久性内存的数据可以是非易失的，断电数据不丢失
持久性内存的耐久性比NAND高出一个数量级，服务器坏了它也还没坏！
持久性内存的容量远远超出DRAM，且可以使用DIMM通道与DRAM共存
集成了PM的应用可以就地更新数据而不用序列化反序列化
PM像内存一样字节寻址，应用程序可以按需修改，而不需要read-modify-write的开销
数据是CPU cache coherent的（缓存一致的）
PM提供DMA和RDMA操作
位于持久性内存上的数据可以从用户空间直接访问，数据路径上没有内核代码，文件系统页缓存或中断

> 什么是PM中的崩溃一致性？

PM作为一个非易失设备，为PM设计存储软件系统时，也面临存储系统普遍存在的崩溃一致性问题(Crash Consistency)，这个问题同时涉及PM的持久性和原子性问题。

系统遭遇断电、崩溃等情况时，相关联的数据没有全部持久化可能导致的不一致，可以在PM上恢复它们的持久数据。但是，这样的恢复需要保证持久数据处于一致状态，这种要求称为崩溃一致性保证

Atomicity即保证请求完全成功或者完全失败，Consistency即保证存储系统中所有元数据之间甚至元数据和数据之间是一致的或者说合理的，Isolation即在并发的情况下，保证两次请求互相不会看到各自执行到一半的状态，Durability即保证存储系统的某次请求若执行完成则相关的数据一定已经被写到存储设备中。


> 什么是原子性？

这里的原子性指的是原子更新粒度(原子操作)或并发时的原子可见性(隔离性)，而非ACID事务的原子性。虽然ACID事务的原子性也是需要借助原子操作实现，这里的原子性更类似与ACID中的I(isolation, 隔离性)。


> 什么是合并写？

现代CPU采用了大量的技术来抵消内存访问带来的延迟。读写内存数据期间，CPU能执行成百上千条指令。

那怎么办呢？提出了使用缓存技术，什么是缓存呢？，原始意义是指访问速度比一般随机存取存储器（RAM）快的一种高速存储器，通常它不像系统主存那样使用DRAM技术，而使用昂贵但较快速的SRAM技术。缓存的设置是所有现代计算机系统发挥高性能的重要因素之一。

多级SRAM缓存是减小这种延迟带来的影响的主要手段。此外，SMP系统采用消息传递协议来实现缓存之间的一致性。遗憾的是，现代的CPU实在是太快了，即使是使用了缓存，有时也无法跟上CPU的速度。因此，为了进一步减小延迟的影响，一些鲜为人知的缓冲区派上了用场。

本文将探讨“合并写存储缓冲区（write combining store buffers）”，以及如何写出有效利用它们的代码。


CPU缓存是一种高效的非链式结构的hash map，每个桶（bucket）通常是64个字节。这就是一个“缓存行（cache line）”。缓存行是内存交换的实际单位。例如，主存中地址A会映射到一个给定的缓存行C。


如果CPU需要访问的地址hash后的行尚不在缓存中，那么缓存中对应位置的缓存行会被清除，以便载入新的行。例如，如果我们有两个地址，通过hash算法hash到同一缓存行，那么新的值会覆盖老的值。

当CPU执行存储指令（store）时，它会尝试将数据写到离CPU最近的L1缓存。如果此时出现缓存未命中，CPU会访问下一级缓存。此时，无论是英特尔还是许多其它厂商的CPU都会使用一种称为“合并写（write combining）”的技术。

在请求L2缓存行的所有权尚未完成时，待存储的数据被写到处理器自身的众多跟缓存行一样大小的存储缓冲区之一。这些芯片上的缓冲区允许CPU在缓存子系统准备好接收和处理数据时继续执行指令。当数据不在任何其它级别的缓存中时，将获得最大的优势。

当后续的写操作需要修改相同的缓存行时，这些缓冲区变得非常有趣。在将后续的写操作提交到L2缓存之前，可以进行缓冲区写合并。 这些64字节的缓冲区维护了一个64位的字段，每更新一个字节就会设置对应的位，来表示将缓冲区交换到外部缓存时哪些数据是有效的。

> 什么是顺序写模型

顺序写(ordered write)模型： 规定一组原子的数据存储单元间有一定的因果顺序(或依赖关系)，先存的数据不依赖于后存的数据，因此，当数据按这个顺序存储到存储设备的过程中，无论何时发生断电或崩溃，系统仍是一致的。

早期的Unix文件系统FFS便是以同步写的方式保证写的顺序性，但是同步导致的阻塞降低了性能；与这种低效但一致的机制相反，若挂载FFS时加入async选项，FFS的所有写操作便异步且无序地进行，虽然这样性能会很好，但顺序一致性无法保证，系统崩溃可能会导致文件系统的损坏。Soft updates方案则是将同步顺序写改为异步顺序写，兼顾了性能和一致性。SoupFS就是在Soft updates方案基础上针对PM进行改进的PM感知文件系统。

> 什么是事务(transactional)模型：

规定某一组原子的数据单元间是存在相互依赖关系的，先存的数据和后存的数据相互依赖，因此，只有保证整组数据全部存到磁盘或者全部没有存到存储设备，系统才是一致的。

由于原子写粒度小于整组数据大小或者数据分散于多个写单元这两种情况是非常常见的，使用事务模型就需要额外的机制保证事务一致性，比如logging(journaling)、log-structuring、copy-on-write等。

显然，顺序写模型对一致性的要求弱于事务模型。而且，事务模型一般就是建立在顺序写模型基础上的(比如日志要先于数据写到磁盘上)。使用哪种模型要取决于所存数据的实际依赖关系和系统设计者对系统一致性的需求。例如，要保证文件系统的bitmap和inode两种metadata之间的一致性就必须采用事务模型，因为文件系统中bitmap的用于指示存储空间的分配状况，各个文件的inode也存储有各个文件的大小及数据块位置，那么这两种数据便存在相互依赖关系，在用户对某个文件的写操作导致文件增大时，bitmap和inode需要同时改变，在这次用户操作前后的一致性就必须采用事务模型保证。


> 什么是copy on write

写入时复制（CopyOnWrite，简称COW）思想是计算机程序设计领域中的一种通用优化策略。其核心思想是，如果有多个调用者（Callers）同时访问相同的资源（如内存或者是磁盘上的数据存储），他们会共同获取相同的指针指向相同的资源，直到某个调用者修改资源内容时，系统才会真正复制一份专用副本（private copy）给该调用者，而其他调用者所见到的最初的资源仍然保持不变。这过程对其他的调用者都是透明的（transparently）。此做法主要的优点是如果调用者没有修改资源，就不会有副本（private copy）被创建，因此多个调用者只是读取操作时可以共享同一份资源。

通俗易懂的讲，写入时复制技术就是不同进程在访问同一资源的时候，只有更新操作，才会去复制一份新的数据并更新替换，否则都是访问同一个资源。

JDK 的 CopyOnWriteArrayList/CopyOnWriteArraySet 容器正是采用了 COW 思想，它是如何工作的呢？简单来说，就是平时查询的时候，都不需要加锁，随便访问，只有在更新的时候，才会从原来的数据复制一个副本出来，然后修改这个副本，最后把原数据替换成当前的副本。修改操作的同时，读操作不会被阻塞，而是继续读取旧的数据。这点要跟读写锁区分一下。


> 可伸缩内存分配器

现有的内存分配器通常预先定义一组对象大小类。对于每个size类，分配器维护一个该大小的空闲内存块列表。分配请求由最接近大小的类中的列表来满足。当选择的大小类大于请求的大小时，就会发生内存碎片。与易失性内存不同，PM上的碎片具有更持久的影响。易失性内存可以重新启动程序以减少碎片，而PM上的碎片通过重新启动而持续存在。另外，PM分配器需要确保元数据处于一致的状态，以避免崩溃后的数据丢失和内存泄漏

由于网上的资料也是查找了，发现关于这个内存分配器的也很少。

> 什么是bitmap

Bit即比特，是目前计算机系统里边数据的最小单位，8个bit即为一个Byte。一个bit的值，或者是0，或者是1；也就是说一个bit能存储的最多信息是2。
Bitmap可以理解为通过一个bit数组来存储特定数据的一种数据结构；由于bit是数据的最小单位，所以这种数据结构往往是非常节省存储空间。比如一个公司有8个员工，现在需要记录公司的考勤记录，传统的方案是记录下每天正常考勤的员工的ID列表，比如2012-01-01:[1,2,3,4,5,6,7,8]。假如员工ID采用byte数据类型，则保存每天的考勤记录需要N个byte，其中N是当天考勤的总人数。另一种方案则是构造一个8bit（01110011）的数组，将这8个员工跟员工号分别映射到这8个位置，如果当天正常考勤了，则将对应的这个位置置为1，否则置为0；这样可以每天采用恒定的1个byte即可保存当天的考勤记录。
综上所述，Bitmap节省大量的存储空间，因此可以被一次性加载到内存中。再看其结构的另一个更重要的特点，它也显现出巨大威力：就是很方便通过位的运算（AND/OR/XOR/NOT），高效的对多个Bitmap数据进行处理，这点很重要，它直接的支持了多维交叉计算能力。比如上边的考勤的例子里，如果想知道哪个员工最近两天都没来，只要将昨天的Bitmap和今天的Bitmap做一个按位的“OR”计算，然后检查那些位置是0，就可以得到最近两天都没来的员工的数据了，比如：

 

> 新兴PM架构

新兴的持久内存是字节寻址的，PM内存直接连接到内存总线，就像传统的DRAM内存一样。处理器可以通过加载和存储指令访问PM。
英特尔Optane直流PM代表了最先进的PM硬件[34,57,58,71]。
处理器和PM之间的数据传输在缓存线粒度(64字节)上进行。然而，Optane内部事务的粒度为256字节。写入放大是两个不匹配的事务大小的结果。例如，更新缓存线(64字节)可能导致Optane媒体中256字节的写入。每个NVDIMM内部都有一个16KB的合并缓冲区[34]来合并写操作。如果处理器的多个写操作占用一个连续的256字节块，那么它们可以被组合成一个事务。


> 性能的表征

图2a显示了PM事务中写操作的延迟分解。我们报告了小(64字节)和大(512字节)持久化对象的性能。图中显示，大部分时间花在日志更新或元数据更新上。

图2b报告了在对512字节持久化对象执行写操作的事务中持久化数据大小的分布。该图显示，78%以上的持久化对象小于64字节。，大量的小写在PM。此外，我们还研究了写入放大，将其量化为PM中由性能计数器测量的写流量与被事务修改的字节数之间的比率。

图2c报告了对64字节和512字节持久化对象执行写操作的事务中的写放大。所有系统都具有写入放大功能，使PM写入流量增加1.8x - 27x


图3报告了在PM和DRAM上使用24个线程执行100M写的带宽。我们对高性能PM事务有以下观察和见解。

图3a和图3b显示PM的写带宽明显低于DRAM。
由于上面也说道，基于日志的事务系统需要写数据两次来更新持久对象，这会导致过多的写流量。

图3a显示了PM上的小的随机写操作比顺序写操作的性能更差。当只写64字节时(图3a)，随机写只能达到顺序写带宽的25%。这种性能差距是由256字节的Optane内部粒度和写入放大造成的，当写入大小增加时，差距会减小。基于日志的事务就地更新持久对象。这可能会导致随机写操作，因为事务中的持久对象可以随机分布在PM上。使用位置外更新(就像在基于cow的事务中那样)可以启用顺序写操作，因为持久对象的新副本是可管理的，并且可以在PM中连续布局。

图3a显示了PM上的随机写在写大小上的性能峰值是256字节的倍数，例如4和8条缓存线。相反，DRAM上的随机写操作(图3b)没有这样的模式。PM上的这种性能是由于写组合缓冲区的影响。它缓冲64字节存储并将其合并为一个256字节的内部存储。对连续地址空间的小并发写比对任意地址的小并发写更有可能合并到一个内部存储器中。因此，增加对连续地址空间的并发写操作的可能性可以增加利用组合缓冲区硬件来合并PM内部写操作的机会


<hr/>

## 设计原则


TM架构也是一个PM事物系统，包含了两个原则，一个是避免小写，一个鼓励顺序写。
什么是小写呢？一般情况下在向内存写数据时，数据也是有大有小的，但是小于256字节的数据一般都是小写，PM中的小写会导致写放大，因为小写中的数据必须与PM中的内部写块大小(256字节)对齐，这会浪费内存带宽并延迟事务，但是研究表明，当事务系统执行写操作时，超过78%的数据对象小于64字节。

作者使用了类似``cow``的设计来避免基于日志的事务中的双重写问题。为了避免小的写操作，ArchTM将内存分配器元数据和数据对象存储在DRAM上，减少对PM频繁的小的随机写操作。然而，这样的设计会在性能和崩溃一致性之间进行基本的权衡。特别是DRAM上的元数据，尽管会导致高事务性能，但在崩溃发生时可能会丢失，从而导致识别数据对象崩溃一致性的问题。


(1) Logless。ArchTM倾向于使用CoW机制来减少对PM的写流量。

(2)最小化PM上的元数据修改，保证崩溃一致性。ArchTM将瞬态元数据保存在DRAM上，以避免在PM上频繁修改元数据。此外，ArchTM还引入了一种注释机制来连接持久化事务状态和数据对象。ArchTM可以从数据对象的事务状态中检测PM上数据的一致性，并从崩溃中恢复。

(3)可伸缩的持久化对象引用。ArchTM在DRAM上使用一个可伸缩的对象查找表来快速定位并发事务中持久对象的最新副本。


•鼓励合并写。
(4)连续的分配请求获得连续的内存块。ArchTM为小内存分配支持位置感知的数据路径，以鼓励事务中的顺序写操作。
(5)避免内存碎片。ArchTM采用了一种轻量级的在线内存碎片整理技术，它可以按区域检查内存使用情况，并减少PM上的碎片。

在PM上，顺序写比随机写快得多(例如，对于64字节的写，顺序写比随机写快3.7倍)。多个顺序写操作可以合并到Optane的内部缓冲区中，从而实现高性能



由于在上述也说道，小写的数据量是占大多数的，所以也可以从3a图看出，顺序写更有利于小写而不是大写，所以小分配是主要的优化对象



> 数据结构

该内存池被划分为元数据和用户数据区域。如图4所示，元数据区域存储一个根对象、一个事务状态变量列表、一个检查点字段(CHKP)和一个检查点-diff字段(CHKP-diff)。

事务状态变量列表记录每个正在进行的事务的状态。每个变量编码事务状态和ID，以及提交ID。我们使用事务开始时间戳作为事务ID，事务提交时间戳作为提交ID。它们是在事务开始和结束时捕获的全局时间戳。ArchTM使用硬件时钟(x86架构中的rdtscp[6,36])，并通过ORDO原语[36]防止处理器之间的硬件时钟持续倾斜，以确保事务的正确排序。事务状态表示事务的进度，例如BEGIN、COMMITTED、END或ABORT。

CHKP存储对象查找表的一个持久检查点，以加速恢复(第5.6节)。CHKP-diff记录预先分配给每个线程的内存块(命名内存段)列表(章节5.4-分配)。CHKP-diff对于在下一个检查点之前跟踪工作对象非常有用。它被实现为包含三个字段的元素数组:获取段的正在进行的事务的ID，段的起始地址和大小。
用户数据区域存储持久化对象。每个对象都有一个对象头和数据。头包含对象ID、大小和事务ID。

用户数据区域将其划分为用于大型对象分配的常规数据路径区域和用于小型对象分配的位置感知数据路径区域


<hr/>

ArchTM主存:

每个事务包含一个对象查找表和一个散列集。对象查询表是一个一维数组，将持久对象ID映射到PM上的持久对象。每个PM对象在表中都有一个条目。一个条目有四个字段。，一个指向最新副本的指针(new)，一个指向旧副本的指针(old)，一个变量(命名为writer)，该变量存储修改最新副本的正在进行的事务的事务状态变量的指针，以及一个与写入者关联的用于协调并行事务的写锁。散列集(名为write-set)用于收集活动事务中线程修改的所有持久对象的id。在提交事务之前，必须持久化散列集中的所有对象。

ArchTM管理DRAM上两个分配器的元数据。当创建持久对象时，第一个分配器在对象查找表中分配一个条目。这个分配器为每个核维护一个持久对象的空闲ID列表(命名ID列表)。持久对象ID是对象查找表中条目的索引。当分配器分配一个条目时，它从ID列表中获得一个对象ID。当释放一个持久对象时，将其对象ID返回到ID列表。我们为持久对象重用id，以避免id爆炸。只有当ID列表为空时，才会创建新的ID。

第二个分配器分配持久对象。它重用JEMalloc[23]中的元数据结构作为常规数据路径，但添加了重要的扩展来优化PM的小写(章节4)。对于位置感知的数据路径，ArchTM维护了一个全局空闲列表和一个全局回收列表。全局空闲列表包含可供分配的内存块。当多个线程访问全局空闲列表时，为了确保顺序，ArchTM对全局空闲列表使用写锁。为了减少全局空闲列表上的争用，每个线程维护一个线程专用分配列表，它是全局空闲列表的一部分。只有当一个线程用完它的分配列表时，这个线程才会访问全局空闲列表来获得一个新的部分。因此，在全局空闲列表上同步是不常见的。全局回收列表收集所有线程释放的内存块。分配器为每个线程管理一个回收列表，以收集回收的内存块。来自这些线程本地回收列表的块将被收集、排序并合并到全局回收列表中。


> 核心操作

ArchTM支持五种核心操作，即事务的开始、读、写、提交和后提交。ArchTM提供快照隔离[8,13]，类似于现有的工作[12,27,45,48,55,63]和工业生产数据库系统[2-5,7,53]。我们演示了算法1和算法2中的运算。


APT_TX_BEGIN启动一个事务，并根据全局时间戳(Alg. 1第2行)为该事务分配一个唯一的ID (TxID)。事务状态变量(TxState)被创建并存储在PM的元数据区域中。TxState是TxID、状态和事务提交ID (CommitID)的组合。在事务开始时，ArchTM通过原子写将TxID和状态BEGIN添加到TxState中。
APT_TX_READ返回一个指针，该指针指向带有(ob jID)的持久对象副本。如果对象没有被任何事务更新(Alg. 1第9行)，则返回指向旧副本的指针。如果对象被当前事务(Alg. 1第11行)或当前事务开始之前提交的事务(Alg. 1第13行)更新，则返回指向新副本的指针。否则，ArchTM返回旧副本的指针。整个过程是无锁的。

APT_TX_WRITE返回一个指向准备更新的持久化对象ob jID的指针。如果持久对象已经有一个新的副本，并且当前事务执行了对该副本的最新更新，则返回指向新副本的指针(Alg. 1第20-22行)。如果持久化对象没有新的副本，应用程序线程会分配一个，

		
获取对象的写入者的写锁(Alg. 1第23行)，将旧副本复制到新副本，然后更新新副本。应用程序线程还将对象ID插入到写集中。如果应用程序线程无法获得该对象的写锁，APT_TX_WRITE将中止并在一个新的事务中重试。
APT_TX_ON_COMMIT提交一个事务。如果事务是只读的，则不会执行持久操作。否则，ArchTM将写入集中记录的修改过的对象持久化到PM (Alg. 2第4-5行)。之后，ArchTM获得一个全局时间戳作为CommitID，并通过原子写将事务状态变量中的CommitID更新为COMMITTED。


清空已提交的事务。首先，它检查在当前事务完全提交之前是否有任何正在进行的事务(Alg. 2第13-16行)。它收回了旧的副本。(将旧的副本放入线程私有释放列表中)。这确保了在任何正在进行的事务中不再需要持久对象的旧副本。然后，ArchTM将新副本设置为旧副本，并将新副本设置为NULL。最后，它重置并解锁修改对象的写入器。ArchTM还将事务状态更新并持久化到END, CommitID更新到INF。




